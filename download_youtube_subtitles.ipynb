{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdu71/RjFP+mcyVdN6++fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pakmingc/download-youtube-subtitles/blob/main/download_youtube_subtitles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from yt_dlp import YoutubeDL\n",
        "from google.colab import drive\n",
        "\n",
        "# Install required libraries\n",
        "!pip install youtube_transcript_api\n",
        "!pip install yt_dlp\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrwvFrnb-cuM",
        "outputId": "1b225891-38bd-440b-95ed-508cec84f0d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2024.2.2)\n",
            "Requirement already satisfied: yt_dlp in /usr/local/lib/python3.10/dist-packages (2024.3.10)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2024.2.2)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (3.20.0)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.0.7)\n",
            "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt_dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt_dlp) (3.6)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_subs(video_id):\n",
        "    try:\n",
        "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "        primary_transcript = None\n",
        "\n",
        "        # Prioritize finding English subtitles\n",
        "        try:\n",
        "            primary_transcript = transcript_list.find_transcript(['en'])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # If English subtitles are not available, look for Chinese subtitles\n",
        "        if not primary_transcript:\n",
        "            try:\n",
        "                primary_transcript = transcript_list.find_transcript([\n",
        "                    'yue', 'yue-HK', 'zh', 'zh-HK', 'zh-CN', 'zh-Hans',\n",
        "                    'zh-SG', 'zh-Hant', 'zh-TW'\n",
        "                ])\n",
        "            except:\n",
        "                print(\"English and all possible Chinese subtitles are not available.\")\n",
        "                return None\n",
        "\n",
        "        primary_transcript.fetch()\n",
        "        subs = []\n",
        "        for line in primary_transcript.fetch():\n",
        "            subs.append(line['text'])\n",
        "        return '\\n'.join(subs)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download subtitles: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_video_title(video_id):\n",
        "    ydl_opts = {}\n",
        "    with YoutubeDL(ydl_opts) as ydl:\n",
        "        info_dict = ydl.extract_info(video_id, download=False)\n",
        "        return info_dict.get('title', None)\n",
        "\n",
        "def main(video_url_or_id):\n",
        "    video_id = re.search(r'(?<=v=)[^&#]+', video_url_or_id)\n",
        "    video_id = video_id.group(0) if video_id else video_url_or_id\n",
        "\n",
        "    title = get_video_title(video_id)\n",
        "    if not title:\n",
        "        print(\"Unable to retrieve video title.\")\n",
        "        return\n",
        "\n",
        "    subs = download_subs(video_id)\n",
        "    if subs:\n",
        "        save_path = f\"/content/drive/My Drive/youtube_subtitles/{title}.txt\"\n",
        "        with open(save_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(subs)\n",
        "        print(f\"Subtitles saved to: {save_path}\")\n",
        "        print(\"Subtitle content:\")\n",
        "        print(subs)\n",
        "    else:\n",
        "        print(\"Unable to download subtitles.\")\n",
        "\n",
        "while True:\n",
        "    # Prompt user for YouTube video URL or ID\n",
        "    video_url_or_id = input(\"Enter the YouTube video URL or ID (or type 'the end' to quit): \")\n",
        "\n",
        "    if video_url_or_id.lower() == 'the end':\n",
        "        print(\"Program ended.\")\n",
        "        break\n",
        "\n",
        "    # Run the main function\n",
        "    main(video_url_or_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehsz_rFn_0zl",
        "outputId": "74247570-59c1-4484-e506-b24e1264fc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the YouTube video URL or ID (or type 'the end' to quit): https://www.youtube.com/watch?v=WxYC9-hBM_g\n",
            "[youtube] Extracting URL: WxYC9-hBM_g\n",
            "[youtube] WxYC9-hBM_g: Downloading webpage\n",
            "[youtube] WxYC9-hBM_g: Downloading ios player API JSON\n",
            "[youtube] WxYC9-hBM_g: Downloading android player API JSON\n",
            "[youtube] WxYC9-hBM_g: Downloading m3u8 information\n",
            "Subtitles saved to: /content/drive/My Drive/youtube_subtitles/Run your own AI (but private).txt\n",
            "Subtitle content:\n",
            "I'm running something called private\n",
            "ai. It's kind of like chat GPT,\n",
            "except it's not. Everything about it\n",
            "is running right here on my computer.\n",
            "Am I even connected to the internet?\n",
            "This is private contained and my data\n",
            "isn't being shared with some random\n",
            "company. So in this video I\n",
            "want to do two things. First,\n",
            "I want to show you how to set this up.\n",
            "It is ridiculously easy and fast to run\n",
            "your own AI on your laptop computer or\n",
            "whatever. It's this is free, it's amazing.\n",
            "It'll take you about five minutes and\n",
            "if you stick around until the end,\n",
            "I want to show you something even\n",
            "crazier, a bit more advanced.\n",
            "I'll show you how you can connect\n",
            "your knowledge base, your notes,\n",
            "your documents,\n",
            "your journal entries to your own\n",
            "private GPT and then ask it questions\n",
            "about your stuff. And then second,\n",
            "I want to talk about how private AI is\n",
            "helping us in the area we need help Most.\n",
            "Our jobs, you may not know this,\n",
            "but not everyone can use chat GBT\n",
            "or something like it at their job.\n",
            "Their companies won't let them mainly\n",
            "because of privacy and security reasons,\n",
            "but if they could run their own\n",
            "private ai, that's a different story.\n",
            "That's a whole different ballgame and\n",
            "VMware is a big reason. This is possible.\n",
            "They're the sponsor of this video and\n",
            "they're enabling some amazing things that\n",
            "companies can do on-Prem in their\n",
            "own data center to run their own ai.\n",
            "And it's not just the cloud man,\n",
            "it's like in your data center.\n",
            "The stuff they're doing is crazy. We're\n",
            "going to talk about it here in a bit,\n",
            "but tell you what, go ahead and do\n",
            "this. There's a link in the description.\n",
            "Just go ahead and open it and take a\n",
            "little glimpse at what they're doing.\n",
            "We're going to dive deeper,\n",
            "so just go ahead and have it open right\n",
            "in your second monitor or something or\n",
            "on the side or minimize. I\n",
            "don't know what you're doing.\n",
            "I dunno how many monitors you\n",
            "have. You have three Actually, Bob,\n",
            "I can see before we get started,\n",
            "I have to show you this.\n",
            "You can run your own private ai. That's\n",
            "kind of uncensored. I watch this,\n",
            "So yeah, please don't do\n",
            "this to destroy me. Also,\n",
            "make sure you're paying attention\n",
            "at the end of this video,\n",
            "I'm doing a quiz and if you're one of\n",
            "the first five people to get a hundred\n",
            "percent on this quiz, you're getting\n",
            "some free coffee network. Chuck Coffee.\n",
            "So take some notes,\n",
            "study up. Let's do this\n",
            "now real quick, before we install a\n",
            "private local AI model on your computer,\n",
            "what does it even mean? What's\n",
            "an AI model? At its core,\n",
            "an AI model is simply an artificial\n",
            "intelligence pre-trained on data we\n",
            "provided. One you may have\n",
            "heard of is open AI's Chat GBT,\n",
            "but it's not the only one out\n",
            "there. Let's take a field trip.\n",
            "We're going to go to a website\n",
            "called hugging face.co.\n",
            "Just an incredible brand\n",
            "name. I love it so much.\n",
            "This is an entire community dedicated\n",
            "to providing and sharing AI models and\n",
            "there are a ton. You're about\n",
            "to have your mind blown. Ready?\n",
            "I'm going to click on models up here. Do\n",
            "you see that number? 505,000 AI models.\n",
            "Many of these are open and free\n",
            "for you to use and pre-trained,\n",
            "which is kind of a crazy\n",
            "thing. Let me show you this.\n",
            "We're going to search for\n",
            "a model named Llama two,\n",
            "one of the most popular models out\n",
            "there. We'll do LAMA two seven B. Again,\n",
            "I love the branding.\n",
            "LAMA two is an AI model known as\n",
            "an LLM or large language model,\n",
            "open AI's Chat. GPT is\n",
            "also an LLM. Now this LLM,\n",
            "this pre-trained AI\n",
            "model was made by meda,\n",
            "AKA Facebook and what\n",
            "they did to pre-train.\n",
            "This model is kind of insane and the fact\n",
            "that we're about to download this and\n",
            "use it even crazier, check this out\n",
            "if you scroll down just a little bit,\n",
            "here we go. Training data.\n",
            "It was trained by over 2 trillion\n",
            "tokens of data from publicly available\n",
            "sources. Instruction data sets over\n",
            "a million human annotated examples,\n",
            "data freshness. We're talking\n",
            "in July, 2023. I love that term.\n",
            "Data freshness and getting\n",
            "the data was just step one.\n",
            "Step two is insane because this\n",
            "is where the training happens.\n",
            "Mata to train this model put together\n",
            "what's called a super cluster.\n",
            "It already sounds cool, right?\n",
            "This sucker is over 6,000 GPUs.\n",
            "It took 1.7 million GPU hours to\n",
            "train this model and it's estimated it\n",
            "costs around $20 million to train\n",
            "it and now made is just like,\n",
            "here you go kid. Download this\n",
            "incredibly powerful thing.\n",
            "I don't want to call it a being\n",
            "yet. I'm not ready for that,\n",
            "but this intelligent source of information\n",
            "that you can just download on your\n",
            "laptop and ask it questions,\n",
            "no internet required and this is just\n",
            "one of the many models we could download.\n",
            "They have special models like\n",
            "text to speech, image to image.\n",
            "They even have uncensored ones. They have\n",
            "an uncensored version of a llama too.\n",
            "This guy George Sung,\n",
            "took this model and fine tuned\n",
            "it with a pretty hefty GPU,\n",
            "took him 19 hours and made it to where\n",
            "you could pretty much ask this thing.\n",
            "Anything you wanted, whatever\n",
            "question comes to mind,\n",
            "it's not going to hold back. Okay,\n",
            "so how did we get this fine tuned\n",
            "model onto your computer? Well,\n",
            "actually I should warn you, this\n",
            "involves quite a bit of llamas,\n",
            "more than you would expect. Our\n",
            "journey starts at a tool called O Lama.\n",
            "Let's go ahead and take a field\n",
            "trip out there real quick.\n",
            "We'll go to O lama.ai. All we'll have\n",
            "to do is install this little guy, Mr.\n",
            "Alama,\n",
            "and then we can run a ton of different\n",
            "LLMs Llama two Code Llama told you lots\n",
            "of llamas and there's others that are\n",
            "pretty fun like Llama two Uncensored or\n",
            "Llamas. Tdrl. I'll show you in a second.\n",
            "But first, what do we install alama on?\n",
            "We can see right down here that we\n",
            "have it available on macOS and Linux,\n",
            "but oh bummer, windows coming soon.\n",
            "It's okay because we've got WSL,\n",
            "the Windows subsystem for Linux,\n",
            "which is now really easy to set up.\n",
            "So we'll go ahead and click on\n",
            "download right here from os.\n",
            "You'll just simply download this\n",
            "and install like one of your regular\n",
            "applications for Linux.\n",
            "We'll click on this.\n",
            "We got to fun curl command that will\n",
            "copy and paste now because we're going to\n",
            "install WSL on Windows. This will\n",
            "be the same step. So Mac OS folks,\n",
            "go ahead and just run that installer.\n",
            "Linux and Windows folks, let's keep going.\n",
            "Now, if you're on Windows,\n",
            "all you have to do now to get WSL\n",
            "installed is launch your Windows terminal.\n",
            "Just go to your search bar and search\n",
            "for terminal and with one command it'll\n",
            "just happen. It used to be so much\n",
            "harder, which is WSL dash dash install.\n",
            "It'll go through a few steps.\n",
            "It'll install Ubuntu as default.\n",
            "I'll go ahead and let that do\n",
            "that. And boom, just like that.\n",
            "I've got Ubuntu 22 0 4 3 lts installed\n",
            "and I'm actually inside of it right\n",
            "now. So now at this point, Linux\n",
            "and Windows folks, we converged.\n",
            "We're on the same path.\n",
            "Let's install alama.\n",
            "I'm going to copy that curl\n",
            "command that alama gave us,\n",
            "jump back into my terminal, paste\n",
            "that in there and press enter.\n",
            "Fingers crossed, everything should be\n",
            "great. Like the way it is right now,\n",
            "it'll ask for my pseudo password and\n",
            "that was it. Oh, LAMA is now installed.\n",
            "Now this will directly apply to\n",
            "Linux people and Windows people.\n",
            "See right here where it says Nvidia\n",
            "GPU installed. If you have that,\n",
            "you're going to have a better time\n",
            "than other people who don't have that.\n",
            "I'll show you here in a second.\n",
            "If you don't have it, that's fine.\n",
            "We'll keep going. Now let's run an\n",
            "LLM. We'll start with llama two.\n",
            "So we'll simply type in, oh Lama run,\n",
            "and then we'll pick one llama\n",
            "two and that's it. Ready,\n",
            "set go. It's going to pull the manifest.\n",
            "It'll then start pulling down\n",
            "and downloading Llama two.\n",
            "And I want you to just realize this,\n",
            "that powerful LAMA two pre-training,\n",
            "we talked about all the money and\n",
            "hours spent. That's how big it is.\n",
            "This is the 7 billion\n",
            "parameter model or the seven B.\n",
            "It's pretty powerful and we're about to\n",
            "literally have this in the palm of our\n",
            "hands in like 3, 2, 1. Oh,\n",
            "I thought I had it. Anyways,\n",
            "it's almost done. And boom, it's done.\n",
            "We've got a nice success message\n",
            "right here and it's ready for us.\n",
            "We can ask you anything.\n",
            "Let's try what is a pug?\n",
            "Now the reason this is going\n",
            "so fast, just like a side note,\n",
            "is that I'm running A GPU\n",
            "and AI models love GPUs.\n",
            "So lemme just show you real quick.\n",
            "I did install alama on a Linux\n",
            "virtual machine and I'll just demo the\n",
            "performance for you real quick. By the\n",
            "way, if you're running a Mac with an M1,\n",
            "M two or M three processor, it actually\n",
            "works great. I forgot to install it.\n",
            "I got to install it real quick and\n",
            "I'll ask you that same question.\n",
            "What is a pug? It's going to\n",
            "take a minute, it'll still work,\n",
            "but it's going to be slower on CPUs and\n",
            "there it goes. It didn't take too long,\n",
            "but notice it is a bit slower.\n",
            "Now if you're running WSL and you know\n",
            "have an Nvidia GPU and it didn't show up,\n",
            "I'll show you in a minute how you can\n",
            "get those drivers installed. But anyways,\n",
            "just sit back for a minute,\n",
            "sip your coffee and think\n",
            "about how powerful this is.\n",
            "The tinfoil hat version of me\n",
            "stinking loves this because let's say\n",
            "the zombie apocalypse happens, right?\n",
            "The grid goes down, things are crazy,\n",
            "but as long as I have my\n",
            "laptop and a solar panel,\n",
            "I still have AI and it can help\n",
            "me survive the zombie apocalypse.\n",
            "Let's actually see how that would\n",
            "work. It gives me next steps.\n",
            "I could have it help me with the water\n",
            "filtration system. This is just cool,\n",
            "right? It's amazing. But can\n",
            "I show you something funny?\n",
            "You may have caught this\n",
            "earlier. Who is network? Chuck?\n",
            "What? Dude, I've always\n",
            "wanted to be Rick Grimes.\n",
            "That is so fun, but seriously,\n",
            "it kind of hallucinated there.\n",
            "It didn't have the correct information.\n",
            "It's so funny how it mixed the\n",
            "zombie apocalypse prompt with me.\n",
            "I love that so much. Let's try\n",
            "a different model. I'll say bye.\n",
            "I'll try a really fun one\n",
            "called mytral. And by the way,\n",
            "if you want to know which ones you\n",
            "can run with Llama, which LLMs,\n",
            "they get a page for their models right\n",
            "here and all the ones you can run,\n",
            "including llama two,\n",
            "uncensored Wizard Math.\n",
            "I might give that to my kids\n",
            "actually. Let's see what it says.\n",
            "Now who is Network Chuck?\n",
            "Now my name is not Chuck Davis and my\n",
            "YouTube channel is not called Network\n",
            "Chuck on Tech.\n",
            "So clearly the data this thing was trained\n",
            "on is either not up to date or just\n",
            "plain wrong. So now the question is cool,\n",
            "we've got this local private ai,\n",
            "this LLM, that's super powerful,\n",
            "but how do we teach it the\n",
            "correct information for us?\n",
            "How can I teach it to know\n",
            "that I'm network Chuck,\n",
            "Chuck Keith, not Chuck Davis,\n",
            "and my channel is called Network Chuck.\n",
            "Or maybe I'm a business and I want it\n",
            "to know more than just what's publicly\n",
            "available because sure, right\n",
            "now if you downloaded this lm,\n",
            "you could probably use it in your job,\n",
            "but you can only go so far without it\n",
            "knowing more about your job. For example,\n",
            "maybe you're on a help desk.\n",
            "Imagine if you could take your help\n",
            "desk's knowledge base, your IT procedures,\n",
            "your documentation. Not only that,\n",
            "but maybe you have a database\n",
            "of closed tickets, open tickets.\n",
            "If you could take all that data and\n",
            "feed it to this LLM and then ask it\n",
            "questions about all of\n",
            "that, that would be crazy.\n",
            "Or maybe you wanted to help troubleshoot\n",
            "code that your company's written.\n",
            "You could even make this LM\n",
            "public facing for your customers.\n",
            "You feed information about your product\n",
            "and the customer could interact with\n",
            "that chat bot you make.\n",
            "Maybe this is all possible with a process\n",
            "called fine tuning where we can train\n",
            "this AI on our own proprietary\n",
            "secret private stuff about our\n",
            "company or maybe our lives or\n",
            "whatever you want to use it for,\n",
            "whatever use case is,\n",
            "and this is fantastic because maybe before\n",
            "you couldn't use a public LLM because\n",
            "you weren't allowed to share your\n",
            "company's data with that LLM,\n",
            "whether it's compliance reasons or you\n",
            "just simply didn't want to share that\n",
            "data because it's secret.\n",
            "Whatever the case,\n",
            "it's possible now because\n",
            "this AI is private,\n",
            "it's local and whatever\n",
            "data you feed to it,\n",
            "it's going to stay right there in a\n",
            "company. It's not leaving the door.\n",
            "That idea just makes me so excited\n",
            "because I think it is the future of AI and\n",
            "how companies and individuals\n",
            "will approach it. It's\n",
            "going to be more private.\n",
            "Back to our question though,\n",
            "fine tuning, that sounds cool.\n",
            "Training and AI on your own\n",
            "data, but how does that work?\n",
            "Because as we saw before with\n",
            "pre-training a model with mata,\n",
            "it took them 6,000 GPUs\n",
            "over 1.7 million GPU hours.\n",
            "Do we have to have this massive\n",
            "data center to make this happen? No.\n",
            "Check this out, and this is such a fun\n",
            "example, VMware, they asked chat GPT,\n",
            "what's the latest version\n",
            "of VMware vSphere?\n",
            "Now the latest chat GPT\n",
            "knew about was vSphere 7.0,\n",
            "but that wasn't helpful to VMware because\n",
            "their latest version they were working\n",
            "on chat hadn't been released yet.\n",
            "So it wasn't public knowledge\n",
            "was vSphere eight update too.\n",
            "And they wanted information like this\n",
            "internal information not yet released to\n",
            "the public.\n",
            "They wanted this to be available to\n",
            "their internal team so they could ask\n",
            "something like chat GBT, Hey, what's\n",
            "the latest version of vSphere?\n",
            "And they could answer correctly.\n",
            "So to do what VMware is trying to do\n",
            "to fine tune a model or train it on new\n",
            "data, it does require a lot. First of all,\n",
            "you would need some\n",
            "hardware servers with GPUs.\n",
            "Then you would also need a bunch of\n",
            "tools and libraries and SDKs like PyTorch\n",
            "and TensorFlow, pandas, MPI side\n",
            "kit, learn transformers and fast ai.\n",
            "The list goes on.\n",
            "You need lots of tools and resources\n",
            "in order to fine tune an LLM.\n",
            "That's why I'm a massive fan of\n",
            "what VMware is doing right here.\n",
            "They have something called the\n",
            "VMware private AI with Nvidia,\n",
            "the gajillion things I just listed\n",
            "off. They include in one package,\n",
            "one combo meal, a recipe of\n",
            "ai, fine tuning goodness.\n",
            "So as a company it becomes a bit easier\n",
            "to do this stuff yourself locally.\n",
            "For the system engineer you have on\n",
            "staff who knows VMware and loves it,\n",
            "they could do this stuff,\n",
            "they could implement this and the data\n",
            "scientists they have on staff that will\n",
            "actually do some of the fine tuning,\n",
            "all the tools are right there.\n",
            "So here's what it looks like to fine tune\n",
            "and we're going to kind of peek behind\n",
            "the curtain at what a data\n",
            "scientist actually does.\n",
            "So first we have the infrastructure\n",
            "and we start here in vSphere, VMware.\n",
            "Now if you don't know what vSphere\n",
            "is or VMware, think virtual machines,\n",
            "you got one big physical server. The\n",
            "hardware, the stuff you can feel,\n",
            "touch and smell. You haven't smelled\n",
            "the server, I dunno what you're doing.\n",
            "And instead of installing one operating\n",
            "system on them like Windows or Linux,\n",
            "you install VMware's, EA XI,\n",
            "which will then allow you to virtualize\n",
            "or create a bunch of additional virtual\n",
            "computers. So instead of one computer,\n",
            "you've got a bunch of computers all\n",
            "using the same hardware resources.\n",
            "And that's what we have right here.\n",
            "One of those virtual computers,\n",
            "a virtual machine.\n",
            "This by the way is one of their special\n",
            "deep learning VMs that has all the tools\n",
            "I mentioned and many, many more\n",
            "pre-installed, ready to go.\n",
            "Everything a data scientist could love.\n",
            "It's kind of like a surgeon walking in\n",
            "to do some surgery and like their doctor\n",
            "assistants or whatever have\n",
            "prepared all their tools.\n",
            "It's all in the tray laid out\n",
            "nice and neat to the surgeon.\n",
            "All he has to do is walk\n",
            "in and just go scalpel.\n",
            "That's what we're doing\n",
            "here for the data scientist.\n",
            "Now talking more about hardware,\n",
            "this guy has a couple Nvidia GPUs assigned\n",
            "to it or pass through to it through\n",
            "a technology called PCIE Passthrough.\n",
            "These are some beefy GPUs.\n",
            "I notice they are V GPU for virtual GPU\n",
            "similar to what you do with the CPU,\n",
            "cutting up the PU and assigning some\n",
            "of that to a virtual CPU on a virtual\n",
            "machine. So here we are in data scientists\n",
            "world. This is a Jupiter notebook,\n",
            "a common tool used by a data scientist,\n",
            "and what you're going to see here is a\n",
            "lot of code that they're using to prepare\n",
            "the data,\n",
            "specifically the data that they're\n",
            "going to train or fine tune the existing\n",
            "model on. Now we're not\n",
            "going to dive deep on that,\n",
            "but I do want you to see\n",
            "this, check this out.\n",
            "A lot of this code is all about getting\n",
            "the data ready. So in VMware's case,\n",
            "it might be a bunch of the knowledge\n",
            "base product documentation and they're\n",
            "getting it ready to be fed to the LLM.\n",
            "And here's what I wanted you to see.\n",
            "Here's the dataset that we're training\n",
            "this model on. We're fine tuning.\n",
            "We only have 9,800 examples that we're\n",
            "giving it or 9,800 new prompts or\n",
            "pieces of data. And that\n",
            "data might look like this,\n",
            "like a simple question or a prompt and\n",
            "then we feed it the correct answer and\n",
            "that's how we essentially\n",
            "train ai. But again,\n",
            "we're only giving it 9,800 examples,\n",
            "which is not a lot at all and is\n",
            "extremely small compared to how the\n",
            "model was originally trained.\n",
            "And I point that out to say that we're\n",
            "not going to need a ton of hardware or a\n",
            "ton of resources to fine tune this model.\n",
            "We won't need the 6,000 GPUs we needed\n",
            "for MATA to originally create this model.\n",
            "We're just adding to it,\n",
            "changing some things or fine tuning it\n",
            "to what our use case is and looking at\n",
            "what actually will be changed\n",
            "when we run this and we train it,\n",
            "we're only changing 65 million parameters,\n",
            "which sounds like a lot, right?\n",
            "But not in the grand scheme of things\n",
            "of like a 7 billion parameter model.\n",
            "We're only changing 0.93% of the model.\n",
            "And then we can actually\n",
            "run our fine tuning,\n",
            "which this is a specific technique in\n",
            "fine tuning called prompt tuning where we\n",
            "simply feed up additional prompts with\n",
            "answers to change how it'll react to\n",
            "people asking you questions.\n",
            "This process will take three to four\n",
            "minutes to fine tune it because again,\n",
            "we're not changing a lot and that is\n",
            "just so super powerful and I think VMware\n",
            "is leading the charge with private ai.\n",
            "VMware and Nvidia take all the guesswork\n",
            "out of getting things set up to fine\n",
            "tune an LLM. They've\n",
            "got deep learning VMs,\n",
            "which are insane VMs that\n",
            "come pre-installed with\n",
            "everything you could want\n",
            "everything a data scientist\n",
            "would need to find tune an LLM.\n",
            "Then Nvidia has an entire suite\n",
            "of tools sensor around their GPUs,\n",
            "taking advantage of some really exciting\n",
            "things to help you fine tune your lms.\n",
            "Now there's one thing I didn't talk about\n",
            "because I wanted to save it for last.\n",
            "For right now it's this right\n",
            "here, this vector database,\n",
            "post gray SQL box here.\n",
            "This is something called rag and it's\n",
            "what we're about to do with our own\n",
            "personal GPT here in a bit. Retrieval,\n",
            "augment the generation. So scenario,\n",
            "let's say you have a database of\n",
            "product information, internal docs,\n",
            "whatever it is, and you haven't fine\n",
            "tuned your LLM on this just yet.\n",
            "So it doesn't know about it. You\n",
            "don't have to do that with rag.\n",
            "You can connect your LLM to\n",
            "this database of information,\n",
            "this knowledge base and\n",
            "give it these instructions.\n",
            "Say whenever I ask you a question about\n",
            "any of the things in this database,\n",
            "before you answer, consult the database,\n",
            "go look at it and make sure\n",
            "what you're saying is accurate.\n",
            "We're not retraining the LLM, we're\n",
            "just saying, Hey, before you answer,\n",
            "go check real quick in this database to\n",
            "make sure it's accurate to make sure you\n",
            "got your stuff right.\n",
            "Isn't that cool? So yes,\n",
            "fine tuning is cool and training\n",
            "an LLM on your own data is awesome,\n",
            "but in between those\n",
            "moments of fine tuning,\n",
            "you can have rag set up where\n",
            "it can consult your database,\n",
            "your internal documentation and give\n",
            "correct answers based on what you have in\n",
            "that database. That is so stinking cool.\n",
            "So with VMware private AI\n",
            "foundation with nvidia,\n",
            "they have those tools baked right in\n",
            "to where it just kind of works for what\n",
            "would otherwise be a very complex setup.\n",
            "And by the way, this whole rag thing,\n",
            "like I said earlier,\n",
            "we're about to do this,\n",
            "I actually connected a lot of my notes\n",
            "and journal entries to a private GPT\n",
            "using RAG and I was able to talk\n",
            "with it about me asking it about my\n",
            "journal entries and answering questions\n",
            "about my past. That's so powerful. Now,\n",
            "before we move on,\n",
            "I just want to highlight the fact that\n",
            "Nvidia with their Nvidia AI enterprise\n",
            "gives you some amazing and fantastic\n",
            "tools to pull the LLM of your choice and\n",
            "then fine tune and customize and deploy\n",
            "that LLM. It's all built in right here.\n",
            "So VMware Cloud Foundation,\n",
            "they provide the robust infrastructure\n",
            "and NVIDIA provides all the amazing AI\n",
            "tools you need to develop\n",
            "and deploy these custom LLMs.\n",
            "Now it's not just Nvidia, they're\n",
            "partnering with Intel as well.\n",
            "So VMware is covering all the\n",
            "tools that admins care about.\n",
            "And then for the data\n",
            "scientists, this is for you.\n",
            "Intel's got your back data analytics,\n",
            "generative AI and deep learning tools\n",
            "and some classic ML or machine learning.\n",
            "And they're also working with IBM, all\n",
            "you IBM fans. You can do this too. Again,\n",
            "VMware has the admin's back. But\n",
            "for the data scientist, Watson,\n",
            "one of the first AI things I ever\n",
            "heard about Red Hat and OpenShift,\n",
            "and I love this because what VMware\n",
            "is doing is all about choice.\n",
            "If you want to run your own\n",
            "local private ai, you can.\n",
            "You're not just stuck with one of the\n",
            "big guys out there and you can choose to\n",
            "run it with Nvidia and VMware,\n",
            "Intel and VMware, IBM and VMware.\n",
            "You got options. So there's\n",
            "nothing stopping you.\n",
            "It's not for some of the bonus section\n",
            "of this video and that's how to run your\n",
            "own private GPT with your own\n",
            "knowledge base. Now, fair warning,\n",
            "it is a bit more advanced,\n",
            "but if you stick with me,\n",
            "you should be able to get this up and\n",
            "running. So take one more sip of coffee.\n",
            "Let's get this going. Now, first of\n",
            "all, this will not be using a lama.\n",
            "This will be a separate project\n",
            "called Private GPT. Now disclaimer,\n",
            "this is kind of hard to do.\n",
            "Unlike VMware private ai,\n",
            "which they do it all for you,\n",
            "it's a complete solution for companies\n",
            "to run their own private local ai.\n",
            "What I'm about to show you is not that\n",
            "at all. No affiliation with VMware.\n",
            "It's a free side project.\n",
            "You can try just to get a little taste\n",
            "of what running your own private GPT with\n",
            "rag tastes like. Did I do\n",
            "that right? I don't know.\n",
            "Now L Martinez has a great doc on\n",
            "how to install this. It's a lot,\n",
            "but you can do it. And if\n",
            "you just want a quick start,\n",
            "he does have a few lines of code for\n",
            "Linux and Mac users. Fair warning,\n",
            "this is CPU only. You can't really\n",
            "take advantage of RAG without A GPU,\n",
            "which is what I wanted to do. So\n",
            "here's my very specific scenario.\n",
            "I've got a Windows PC with an\n",
            "NVIDIA 40 90. How do I run this?\n",
            "Linux-based project. WSL, and I'm so\n",
            "thankful to this guy Emelia Lance a lot.\n",
            "He put an entire guide\n",
            "together of how to set this up.\n",
            "I'm not going to walk you through every\n",
            "step because he already did that link\n",
            "below, but I seriously need to buy\n",
            "this guy a coffee. How do I do that?\n",
            "I don't know, Emil, if you're\n",
            "watching this, reach out to me.\n",
            "I'll send you some coffee. So anyways,\n",
            "I went through every step from installing\n",
            "all the prereqs to installing NVIDIA\n",
            "drivers and using poetry to handle\n",
            "dependencies, which poetry is pretty cool.\n",
            "I landed here.\n",
            "I've got a private local working private\n",
            "GPT that I can access through my web\n",
            "browser and it's using my GPU,\n",
            "which is pretty cool. Now,\n",
            "first I try a simple document upload,\n",
            "got this VMware article that details\n",
            "a lot of what we talked about in this\n",
            "video. I upload it and I start asking\n",
            "you questions about this article.\n",
            "I tried something specific like show me\n",
            "something about VMware AI market growth.\n",
            "Bam, it figured it out,\n",
            "it told me. Then I'm like,\n",
            "what's the coolest thing\n",
            "about VMware private ai?\n",
            "It told me I'm sitting here chatting\n",
            "with a document, but then I'm like,\n",
            "let's try something bigger. I\n",
            "want to chat with my journals.\n",
            "I've got a ton of journals on markdown\n",
            "format and I want to ask you questions\n",
            "about me. Now this specific step\n",
            "is not covered in the article.\n",
            "So here's how you do it. First,\n",
            "you'll want to grab your\n",
            "folder of whatever documents\n",
            "you want to ask questions\n",
            "about and throw it onto your machine.\n",
            "So I copied over to my WSL machine and\n",
            "then I ingested it with this command once\n",
            "complete and I ran private GPT. Again,\n",
            "here's all my documents and\n",
            "I'm ready to ask it questions.\n",
            "So let's test this out. I'm going\n",
            "to ask it what did I do in takayama?\n",
            "So I went to Japan in November of 2023.\n",
            "Let's see if you can search my notes,\n",
            "figure out when that was and what I did.\n",
            "That's awesome. Oh my goodness.\n",
            "Let's see, what did I eat in Tokyo?\n",
            "How cool is that? Oh my gosh,\n",
            "that's so fun. No, it's not perfect,\n",
            "but I can see the potential here.\n",
            "That's insane. I love this so much.\n",
            "Private AI is the future and that's why\n",
            "we're seeing VMware bring products like\n",
            "this to companies to run their own\n",
            "private local AI and then make it pretty\n",
            "easy. If you actually did that private\n",
            "GPT thing, that little side project,\n",
            "there's a lot to it. Lots of tools you\n",
            "have to install, it's kind of a pain.\n",
            "But with VMware,\n",
            "they kind of cover everything like that\n",
            "deep learning VM they offer as part of\n",
            "their solution. It's got all the\n",
            "tools ready to go. Pre-baked again,\n",
            "you're like a surgeon just\n",
            "walking in saying scalpel.\n",
            "You got all this stuff right there. So\n",
            "if you want to bring AI to your company,\n",
            "check out VMware private AI link below\n",
            "and thank you to VMware by Broadcom for\n",
            "sponsoring this video. You made it to\n",
            "the end of the video time for a quiz.\n",
            "This quiz will test the knowledge you've\n",
            "gained in this video and the first five\n",
            "people to get a hundred percent on this\n",
            "quiz will get free coffee from Network\n",
            "Chuck Coffee. So here's how\n",
            "you take the quiz right now.\n",
            "Check the description in your\n",
            "video and click on this link.\n",
            "If you're not currently signed into the\n",
            "academy, go ahead and get signed in.\n",
            "If you're not a member, go ahead\n",
            "and click on sign off. It's free.\n",
            "Once you're signed in,\n",
            "it will take you to your dashboard showing\n",
            "you all the stuff you have access to\n",
            "with your free academy account.\n",
            "But to get right back to that quiz,\n",
            "go back to the YouTube video,\n",
            "click on that link once more and\n",
            "it should take you right to it.\n",
            "Go ahead and click on start now and\n",
            "start your quiz. Here's a little preview.\n",
            "That's it. The first five to get\n",
            "a hundred percent free coffee.\n",
            "If you're one of the five,\n",
            "you'll know because you'll\n",
            "receive an email with free coffee.\n",
            "You got to be quick, you got to be smart.\n",
            "I'll see you guys in the next video.\n",
            "Enter the YouTube video URL or ID (or type 'the end' to quit): cWUs1GhBx18\n",
            "[youtube] Extracting URL: cWUs1GhBx18\n",
            "[youtube] cWUs1GhBx18: Downloading webpage\n",
            "[youtube] cWUs1GhBx18: Downloading ios player API JSON\n",
            "[youtube] cWUs1GhBx18: Downloading android player API JSON\n",
            "[youtube] cWUs1GhBx18: Downloading m3u8 information\n",
            "[info] Testing format 616\n",
            "Subtitles saved to: /content/drive/My Drive/youtube_subtitles/【人工智能】2024全球AI产品Top100报告 | A16Z | 五个趋势 | 22家新公司上榜 | AI伴侣崛起 | 网页榜 | 移动榜.txt\n",
            "Subtitle content:\n",
            "大家好，这里是最佳拍档，我是大飞\n",
            "自从一年多前ChatGPT将人工智能生成技术推向公众视野以来\n",
            "我们已经接触了成千上万种\n",
            "融合了人工智能的新型消费级应用\n",
            "包括从视频生成器到工作流程辅助程序\n",
            "从创意工具到虚拟伴侣\n",
            "那么现在生成式AI的应用市场到底是怎么样的呢？\n",
            "今天就跟大家来分享一下\n",
            "A16Z对生成式AI应用最新的市场调研\n",
            "其实在六个月之前\n",
            "A16Z已经对网络流量数据进行了一次深度挖掘\n",
            "根据应用的每月访问量\n",
            "A16Z对最受欢迎的生成式AI网络产品进行了排名\n",
            "虽然早期有几家所谓的赢家引起了广泛关注\n",
            "比如说像ChatGPT和Midjourney\n",
            "但是每个月都有新的人工智能公司涌现出来\n",
            "从而推动市场的动态竞争\n",
            "六个月后的今天\n",
            "A16Z再次更新了这个市场分析\n",
            "根据截至2024年1月的SimilarWeb数据\n",
            "再次对前50的人工智能产品进行了排名\n",
            "令人吃惊的是\n",
            "与六个月前、也就是2023年9月发布的报告相比\n",
            "榜单上有超过40%的公司都是新公司\n",
            "另外，在之前的分析中\n",
            "A16Z是先先根据网页流量对公司进行排名\n",
            "然后再加入这些公司的移动应用数据\n",
            "而这次新的分析\n",
            "是将这些公司的网页和移动排名\n",
            "分成了单独的两个榜单\n",
            "移动应用排名\n",
            "是根据截至2024年1月的Sensor Tower数据\n",
            "按照月活跃用户数量来排序的\n",
            "之所以要把网页和移动数据分开排名\n",
            "是因为这样可以更加全面的区分人工智能移动应用\n",
            "另一个原因是消费者与人工智能的交互方式\n",
            "在网页与移动端之间存在的明显差异\n",
            "这个我们会在后面来详细介绍\n",
            "不过，除了这些排名本身之外\n",
            "调研数据还揭示了一些有关新的应用类型\n",
            "以及人工智能投资和参与模式\n",
            "值得注意的趋势\n",
            "接下来让我们一一道来\n",
            "首先是进步的速度\n",
            "6个月内总共有22家新公司上榜\n",
            "在A16Z六个月前的分析中\n",
            "ChatGPT已经是世界上访问排名第24位的网页\n",
            "现在\n",
            "ChatGPT每月的网络访问量接近20亿次\n",
            "大约是排名第二的Bard\n",
            "也就是现为Gemini的五倍\n",
            "除了Gemini以外，Character\n",
            "AI和写作助手Quillbot也蝉联了前五名的位置\n",
            "不过在这6个月中\n",
            "22家公司新进入了网页流量排行榜\n",
            "在这些新公司中\n",
            "排名最高的是人工智能研究副驾驶Liner、此外还有Anthropic的通用助理AI Claude\n",
            "以及三个未经审查的AI伴侣应用程序\n",
            "分别是JanitorAI、Spicychat和CrushOn\n",
            "这个我们会稍后解释一下\n",
            "为什么会有这么多伴侣应用\n",
            "移动榜单是这次新出的\n",
            "ChatGPT仍然处于领先地位\n",
            "但是差距要小得多\n",
            "就月活跃用户而言\n",
            "ChatGPT的规模大约是排名第二和第三的Microsoft Edge和Photomath的2.5倍\n",
            "在移动产品方面\n",
            "排名前五的是微软的搜索引擎必应\n",
            "实际上是基于AI的新必应\n",
            "以及照片增强和头像工具Remini\n",
            "有趣的是，有五家AI公司是跨界的\n",
            "也就是说既有网页产品\n",
            "也有移动应用\n",
            "它们是ChatGPT、Character\n",
            "AI、聊天机器人聚合器Poe\n",
            "以及图片编辑器Photoroom和Pixelcut\n",
            "其次，在这次的榜单中\n",
            "出现了新的产品类型\n",
            "分别是音乐和生产力工具\n",
            "六个月前A16Z注意到\n",
            "像ChatGPT这样基于大语言模型的通用助手\n",
            "占据了大部分的流量\n",
            "在最新的分析报告中\n",
            "有两个新的类别进入了这一行列\n",
            "就是音乐和生产力工具\n",
            "后者包括了科学研究、辅助编码和文档摘要等任务类型\n",
            "Suno是迄今为止唯一一家进入排行榜的音乐公司\n",
            "它的产品可以根据文本提示\n",
            "在浏览器中生成原创歌曲\n",
            "包括各种风格的歌词\n",
            "Suno起初只是一个发布在Discord上的产品\n",
            "与Midjourney类似\n",
            "但是在2023年12月推出了独立的网页和基于Copilot的扩展\n",
            "这两天又出了新版本V3\n",
            "音乐的生成质量有大幅提升\n",
            "吸引了很多关注\n",
            "有时间我们会做一期节目专门介绍一下\n",
            "不过现在还有一些消费类的AI产品\n",
            "比如Suno\n",
            "最初都是通过Discord服务器起步的\n",
            "或者说现在仍然主要通过Discord来运行\n",
            "因为Discord平台提供了一个试验的场所\n",
            "以及可以进行交流的社区\n",
            "无需完整构建的前端产品\n",
            "由于Discord服务器的真正流量几乎无法测量\n",
            "所以只能把每个服务器邀请页面的网页流量作为衡量标准之一\n",
            "根据这个指标，截止到2024年1月\n",
            "有九个AI产品或者社区\n",
            "跻身了邀请流量排名前100的Discord服务器\n",
            "其中Midjourney名列榜首\n",
            "榜单上第二个值得注意的新类别是生产力工具\n",
            "AI原生的平台可以提升人们与软件的互动水平\n",
            "让人们能够委派日常任务\n",
            "并且减少花在管理上的时间\n",
            "生产力工具类别共有七家公司上榜\n",
            "分别是Linner、Eightify、Phind、MaxAI、Blackbox AI、Otter\n",
            "ai和ChatPDF\n",
            "凭借着流程内编辑和摘要等功能\n",
            "这些产品可以帮助员工、自由职业者和中小企业主更高效地完成工作\n",
            "例如\n",
            "Eightify可以提供YouTube的视频摘要\n",
            "而Otter\n",
            "ai则可以实时记录会议笔记\n",
            "并进行转录\n",
            "在这份榜单上的七款生产力应用程序中\n",
            "有六款可以完全通过谷歌Chrome浏览器扩展运行\n",
            "A16Z相信未来会有更多的AI生产力工具出现\n",
            "能够与用户正在进行的工作同步运行\n",
            "而无需在工作区和ChatGPT等助手之间\n",
            "不断地复制粘贴提示和输出\n",
            "另外\n",
            "AI生产力产品也可以围绕AI的独特功能\n",
            "发明新的端到端工作流程\n",
            "AI工作流程工具可以帮助用户找出可以改进的地方\n",
            "然后自动进行改进\n",
            "第三，AI伴侣发展突飞猛进\n",
            "拥有一个AI伴侣的需求看似小众\n",
            "但是其实现在已经成为了生成式AI的主要用途\n",
            "已经有数百万人与聊天机器人建立了关系\n",
            "无论是网页还是移动数据\n",
            "都预示着社会即将发生转变\n",
            "那就是AI陪伴正在逐渐成为主流\n",
            "六个月前\n",
            "只有两家AI伴侣公司入选了50强名单；\n",
            "而在这次更新的榜单中\n",
            "有八家网页公司和两家移动公司入选\n",
            "Character\n",
            "AI在网页和移动的伴侣工具排行榜中\n",
            "都处于领先地位\n",
            "分别是在网页榜单中排名第3\n",
            "在移动榜单中排名第16\n",
            "八款网页伴侣产品中\n",
            "有六款标榜自己是\"未经审查的\"，\n",
            "这意味着用户可以与它们做一些在ChatGPT等平台上\n",
            "可能会受到限制的对话或者互动行为\n",
            "用户主要通过移动网络来访问这些产品\n",
            "而不是通过电脑\n",
            "尽管这类产品几乎没有一个提供了移动应用程序\n",
            "平均而言\n",
            "网页列表中的这些未经审查的伴侣工具\n",
            "有75%的流量其实来自于移动端\n",
            "对于有移动应用程序的伴侣产品来说\n",
            "参与度异常得高\n",
            "这个类别中最成功的产品\n",
            "已经成为用户日常生活的核心部分\n",
            "就像给朋友发短信一样普遍\n",
            "根据SensorTower的数据，Character\n",
            "AI平均每个用户\n",
            "每月会进行298次会话\n",
            "而Poly\n",
            "AI的用户，平均每月会进行74次会话\n",
            "除了AI\"男朋友\"和AI\"女朋友\"之外\n",
            "也开始出现了一些更广泛的伴侣应用的早期迹象\n",
            "包括友谊、指导、娱乐以及医疗保健\n",
            "事实上，很多早期研究已经表明\n",
            "AI在诊断准确性和态度方面\n",
            "都能胜过真正的医生\n",
            "许多伴侣型产品都是有多面性的\n",
            "在《自然》杂志最近的一项研究中发现\n",
            "Replika聊天机器人减少了3%用户的自杀倾向\n",
            "第四点\n",
            "移动端和网页端之争的背后原因\n",
            "AI的使用方式在移动端应用和网页上有很大的不同\n",
            "一般来说\n",
            "网页端产品支持生成和编辑更复杂的、多步骤的内容工作流程\n",
            "至少目前是这样\n",
            "其中包括AI语音工具ElevenLabs、AI艺术生成器Leonardo\n",
            "和AI PPT生成器Gamma等产品\n",
            "这些产品在基于网页的AI产品排行榜中\n",
            "都排名在前20位\n",
            "与此同时\n",
            "移动端应用程序的使用偏向于通用助理\n",
            "其中许多都模仿ChatGPT\n",
            "在看这些排名靠前的移动端应用程序列表的时候\n",
            "你可能会注意到有10家公司的名称\n",
            "与ChatGPT都非常相似\n",
            "这部分是因为ChatGPT在推出自己的移动端应用程序方面\n",
            "相对较慢\n",
            "这就为模仿者迅速获得App Store的排名优势创造了机会\n",
            "尤其是如果愿意支付广告费用的话\n",
            "一些模仿ChatGPT的移动端应用程序被称为\"诈骗软件\"。\n",
            "它们用类似的标题和标识欺骗用户\n",
            "让用户误以为它们提供的是ChatGPT的高级模型\n",
            "但是事实上\n",
            "它们收取的是访问ChatGPT免费提供的、相同模型的费用\n",
            "这些应用程序经常会更改名称或者描述\n",
            "所以应用商店很难对这种行为进行监管\n",
            "其他一类流行的生成式AI移动应用程序\n",
            "是根据手机的独特功能量身定制的\n",
            "移动应用榜单中有七款专用的头像产品\n",
            "因为大多数人手机中保存的自拍照\n",
            "都是现成的训练数据\n",
            "此外\n",
            "排名第9位的Facemoji、第31位Bobble和第37位的Genie\n",
            "这三款热门应用都是手机上的专用键盘\n",
            "允许用户在AI的帮助下发送文本\n",
            "教育科技是移动领域的另一个热门类别\n",
            "比如像Photomath\n",
            "用户可以用手机扫描作业问题\n",
            "或者是Elsa\n",
            "用户可以通过实时对话来学习语言\n",
            "值得注意的是，根据PitchBook的数据\n",
            "虽然大多数顶级的AI移动应用都是自筹资金开发的\n",
            "但是在七款排名靠前的教育科技移动应用中\n",
            "有四款的融资额已经超过3000万美元\n",
            "最后一个趋势是\n",
            "全球都在热捧AI产品\n",
            "旧金山社区脑谷Cerebral Valley可能是人工智能的中心\n",
            "但是现在世界各地都在开发广受欢迎的AI产品\n",
            "移动应用程序更是如此\n",
            "虽然榜单上有超过30%的新一代AI网页产品源自于湾区\n",
            "但是只有12%的移动应用开发者位于湾区\n",
            "同样\n",
            "虽然一半以上的顶级AI网页产品是在美国开发的\n",
            "但是只有不到三分之一的移动应用程序源自美国\n",
            "一些移动开发者已经获得了多次成功\n",
            "位于伊斯坦布尔的应用程序工作室Codeway\n",
            "开发了AI照片动画工具Face Dance、聊天机器人Chat&Ask AI\n",
            "以及AI艺术生成工具Wonder\n",
            "所有这些应用程序都在AI移动应用程序排行榜上名列前茅\n",
            "同样\n",
            "位于土耳其的HubX开发了聊天机器人Nova、艺术生成工具DaVinci和PhotoApp增强工具\n",
            "这些移动端应用程序工作室\n",
            "通常受益于跨产品的共享专业知识\n",
            "涉及如何推出应用程序、为应用程序吸引流量和盈利等方面\n",
            "其中一些工作室没有筹集任何资金\n",
            "而是专注于尽可能高效地创收\n",
            "还有一些公司则选择了风险投资的道路\n",
            "比如Bending Spoons是一家总部位于米兰的技术公司\n",
            "它是视频编辑器Splice\n",
            "和位居移动排行榜第5位的照片增强工具Remini的幕后推手\n",
            "最近它宣布筹集了1.55亿美元的股权资金\n",
            "显然\n",
            "新一代的AI原生产品和公司的发展速度比以往任何时候都要快\n",
            "吸引用户的程度也比以往任何时候都要深\n",
            "A16Z相信，在未来十年中\n",
            "AI将成为那些改变游戏规则的公司的坚实基础\n",
            "好了\n",
            "以上就是A16Z这次对生成式AI产品的市场调研\n",
            "整个看下来，大飞我个人觉得\n",
            "如果你现在想要在AI领域创业\n",
            "尤其是全球市场\n",
            "那么选择做一个移动端APP的AI个人伴侣\n",
            "可能会是一个不错的机会\n",
            "大家也可以在评论区发表一下自己的看法\n",
            "感谢观看本期视频，我们下期再见\n"
          ]
        }
      ]
    }
  ]
}